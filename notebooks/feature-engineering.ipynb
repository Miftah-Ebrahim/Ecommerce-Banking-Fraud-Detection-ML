{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f15df28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.feature_engineering' from 'c:\\\\Users\\\\hp\\\\Downloads\\\\KAIM\\\\KAIM-WEEK5\\\\Ecommerce-Banking-Fraud-Detection-ML\\\\src\\\\feature_engineering.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Ensure path for src imports\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.preprocessing import preprocess_data\n",
    "import importlib\n",
    "import src.preprocessing\n",
    "import src.feature_engineering\n",
    "importlib.reload(src.preprocessing)\n",
    "importlib.reload(src.feature_engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d2867",
   "metadata": {},
   "source": [
    "# Feature Engineering and Transformation\n",
    "\n",
    "This notebook handles advanced feature creation, encoding, scaling, and imbalance correction for the fraud detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68222a3",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "Load and preprocess the fraud data using existing cleaning functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e178ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: (129146, 17)\n",
      "     user_id         signup_time       purchase_time  purchase_value  \\\n",
      "634   247547 2015-06-28 03:00:34 2015-08-09 03:57:29              47   \n",
      "635   220737 2015-01-28 14:21:11 2015-02-11 20:28:28              15   \n",
      "636   390400 2015-03-19 20:49:09 2015-04-11 23:41:23              44   \n",
      "637    69592 2015-02-24 06:11:57 2015-05-23 16:40:14              55   \n",
      "638   174987 2015-07-07 12:58:11 2015-11-03 04:04:30              51   \n",
      "\n",
      "         device_id  source browser sex  age  ip_address  class  \\\n",
      "634  KIXYSVCHIPQBR     SEO  Safari   F   30    16778864      0   \n",
      "635  PKYOWQKWGJNJI     SEO  Chrome   F   34    16842045      0   \n",
      "636  LVCSXLISZHVUO     Ads      IE   M   29    16843656      0   \n",
      "637  UHAUHNXXUADJE  Direct  Chrome   F   30    16938732      0   \n",
      "638  XPGPMOHIDRMGE     SEO  Chrome   F   37    16971984      0   \n",
      "\n",
      "     lower_bound_ip_address  upper_bound_ip_address    country  \\\n",
      "634              16778240.0              16779263.0  Australia   \n",
      "635              16809984.0              16842751.0   Thailand   \n",
      "636              16843264.0              16843775.0      China   \n",
      "637              16924672.0              16941055.0      China   \n",
      "638              16941056.0              16973823.0   Thailand   \n",
      "\n",
      "     time_since_signup  hour_of_day  day_of_week  \n",
      "634          3632215.0            3            6  \n",
      "635          1231637.0           20            2  \n",
      "636          1997534.0           23            5  \n",
      "637          7640897.0           16            5  \n",
      "638         10249579.0            4            1  \n"
     ]
    }
   ],
   "source": [
    "# Load cleaned fraud data\n",
    "merged_df = preprocess_data(\"../data/raw/Fraud_Data.csv\", \"../data/raw/IpAddress_to_Country.csv\")\n",
    "print(f\"Loaded data shape: {merged_df.shape}\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c8965",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering (Creation)\n",
    "\n",
    "Create time-based, velocity, and frequency features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40b0383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features added:\n",
      "     hour_of_day  day_of_week  time_since_signup  transaction_frequency\n",
      "634            3            6          3632215.0                      1\n",
      "635           20            2          1231637.0                      1\n",
      "636           23            5          1997534.0                      1\n",
      "637           16            5          7640897.0                      1\n",
      "638            4            1         10249579.0                      1\n"
     ]
    }
   ],
   "source": [
    "# Time features\n",
    "merged_df['hour_of_day'] = merged_df['purchase_time'].dt.hour\n",
    "merged_df['day_of_week'] = merged_df['purchase_time'].dt.dayofweek\n",
    "\n",
    "# Velocity feature\n",
    "merged_df['time_since_signup'] = (merged_df['purchase_time'] - merged_df['signup_time']).dt.total_seconds()\n",
    "\n",
    "# Transaction frequency per user\n",
    "user_transaction_count = merged_df.groupby('user_id')['user_id'].transform('count')\n",
    "merged_df['transaction_frequency'] = user_transaction_count\n",
    "\n",
    "print(\"Features added:\")\n",
    "print(merged_df[['hour_of_day', 'day_of_week', 'time_since_signup', 'transaction_frequency']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dbcb5c",
   "metadata": {},
   "source": [
    "## 3. Transformation (Encoding and Scaling)\n",
    "\n",
    "Apply one-hot encoding to categorical features and scaling to numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5123691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after transformation: (129146, 22)\n",
      "     user_id         signup_time       purchase_time  purchase_value  \\\n",
      "634   247547 2015-06-28 03:00:34 2015-08-09 03:57:29        0.549607   \n",
      "635   220737 2015-01-28 14:21:11 2015-02-11 20:28:28       -1.197335   \n",
      "636   390400 2015-03-19 20:49:09 2015-04-11 23:41:23        0.385831   \n",
      "637    69592 2015-02-24 06:11:57 2015-05-23 16:40:14        0.986342   \n",
      "638   174987 2015-07-07 12:58:11 2015-11-03 04:04:30        0.767974   \n",
      "\n",
      "         device_id       age  ip_address  class  lower_bound_ip_address  \\\n",
      "634  KIXYSVCHIPQBR -0.363124    16778864      0              16778240.0   \n",
      "635  PKYOWQKWGJNJI  0.101168    16842045      0              16809984.0   \n",
      "636  LVCSXLISZHVUO -0.479197    16843656      0              16843264.0   \n",
      "637  UHAUHNXXUADJE -0.363124    16938732      0              16924672.0   \n",
      "638  XPGPMOHIDRMGE  0.449387    16971984      0              16941056.0   \n",
      "\n",
      "     upper_bound_ip_address  ... hour_of_day  day_of_week  \\\n",
      "634              16779263.0  ...           3            6   \n",
      "635              16842751.0  ...          20            2   \n",
      "636              16843775.0  ...          23            5   \n",
      "637              16941055.0  ...          16            5   \n",
      "638              16973823.0  ...           4            1   \n",
      "\n",
      "     transaction_frequency  source_Direct  source_SEO  browser_FireFox  \\\n",
      "634                      1          False        True            False   \n",
      "635                      1          False        True            False   \n",
      "636                      1          False       False            False   \n",
      "637                      1           True       False            False   \n",
      "638                      1          False        True            False   \n",
      "\n",
      "     browser_IE  browser_Opera  browser_Safari  sex_M  \n",
      "634       False          False            True  False  \n",
      "635       False          False           False  False  \n",
      "636        True          False           False   True  \n",
      "637       False          False           False  False  \n",
      "638       False          False           False  False  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "categorical_cols = ['source', 'browser', 'sex']\n",
    "encoded_df = pd.get_dummies(merged_df[categorical_cols], drop_first=True)\n",
    "merged_df = pd.concat([merged_df.drop(categorical_cols, axis=1), encoded_df], axis=1)\n",
    "\n",
    "# Scaling (only numerical features, exclude one-hot and target)\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['purchase_value', 'age']\n",
    "merged_df[numerical_cols] = scaler.fit_transform(merged_df[numerical_cols])\n",
    "\n",
    "print(f\"Data shape after transformation: {merged_df.shape}\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9fb7ac",
   "metadata": {},
   "source": [
    "## 4. Imbalance Handling (SMOTE)\n",
    "\n",
    "Split data and apply SMOTE to the training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea7521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape before SMOTE: (103316,)\n",
      "class\n",
      "0    93502\n",
      "1     9814\n",
      "Name: count, dtype: int64\n",
      "y_train shape after SMOTE: (187004,)\n",
      "class\n",
      "0    93502\n",
      "1    93502\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = merged_df.drop(['class', 'user_id', 'signup_time', 'purchase_time', 'device_id', 'ip_address', 'lower_bound_ip_address', 'upper_bound_ip_address'], axis=1).select_dtypes(include=[float, int, bool])\n",
    "y = merged_df['class']\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"y_train shape before SMOTE: {y_train.shape}\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Apply SMOTE to training data only\n",
    "# Since SMOTE is not available, using simple oversampling with resample\n",
    "train_data = X_train.copy()\n",
    "train_data['class'] = y_train\n",
    "\n",
    "majority = train_data[train_data['class'] == 0]\n",
    "minority = train_data[train_data['class'] == 1]\n",
    "\n",
    "minority_oversampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
    "\n",
    "train_oversampled = pd.concat([majority, minority_oversampled])\n",
    "\n",
    "X_train_sm = train_oversampled.drop('class', axis=1)\n",
    "y_train_sm = train_oversampled['class']\n",
    "\n",
    "print(f\"y_train shape after SMOTE: {y_train_sm.shape}\")\n",
    "print(y_train_sm.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6794018a",
   "metadata": {},
   "source": [
    "## 5. Save Processed Data\n",
    "\n",
    "Save the training and test sets to processed folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5e0e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save training data (SMOTE applied)\n",
    "train_df = pd.concat([X_train_sm, y_train_sm], axis=1)\n",
    "train_df.to_csv('../data/processed/train_enc_smote.csv', index=False)\n",
    "\n",
    "# Save test data (untouched)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_df.to_csv('../data/processed/test_enc.csv', index=False)\n",
    "\n",
    "print(\"Data saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
